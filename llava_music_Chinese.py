import streamlit as st
st.set_page_config(page_title="MetaTone Lab", layout="wide")

import sys
import os
import subprocess
import tempfile
import json
import numpy as np
from PIL import Image
from streamlit_drawable_canvas import st_canvas
import random
import music21
import pyphen
from midi2audio import FluidSynth
import torch

print("Python executable:", sys.executable)

# =============== ä½ çš„è¾…åŠ©å‡½æ•° ===============
from util.image_helper import create_temp_file
from util.llm_helper import analyze_image_file, stream_parser

# =============== SoundFont è·¯å¾„ï¼ˆè¯·ç¡®ä¿è·¯å¾„æ­£ç¡®ï¼‰===============
SOUNDFONT_PATH = "/Users/xiangxiaoxin/Documents/GitHub/FaceTune/soundfonts/VocalsPapel.sf2"

# =============== session_state å­˜å‚¨æ­Œè¯å’Œæ ‡é¢˜ ===============
if "lyrics" not in st.session_state:
    st.session_state["lyrics"] = None
if "song_title" not in st.session_state:
    st.session_state["song_title"] = None

# =============== é¡µé¢æ ·å¼ï¼ˆä»…è°ƒç”¨ä¸€æ¬¡ï¼‰===============
st.markdown(
    """
    <style>
    .main .block-container { max-width: 1200px; margin: auto; }
    h1 { text-align: center; font-size: 36px !important; margin-bottom: 0.2em; }
    .subheader-text { font-size: 20px; font-weight: bold; margin-bottom: 0.6em; margin-top: 0.2em; }
    .song-title { font-size: 24px; font-weight: bold; margin-top: 0.5em; margin-bottom: 0.5em; }
    .lyrics-container { height: 500px; overflow-y: auto; padding-right: 1em; margin-top: 10px; border: 1px solid #ccc; border-radius: 5px; }
    .lyrics-container p { line-height: 1.6; margin-bottom: 0.8em; margin-left: 0.5em; margin-right: 0.5em; }
    .stButton { margin-top: 1em; margin-bottom: 1em; }
    div[data-baseweb="slider"] { width: 500px !important; }
    </style>
    """,
    unsafe_allow_html=True
)
st.markdown("<h1>MetaTone å®éªŒå®¤</h1>", unsafe_allow_html=True)


# =============== 1) ç”Ÿæˆæ­Œè¯ (è°ƒç”¨ llava:7b) ===============
def generate_lyrics_with_ollama(image: Image.Image) -> str:
    """
    è°ƒç”¨ llava:7b æ¨¡å‹ï¼Œæ ¹æ®å›¾åƒç”ŸæˆåŒè¯­æ­Œè¯ï¼š
    æ¯å¥ä¸­æ–‡æ­Œè¯ä¸‹æ–¹ç´§è·Ÿä¸€è¡Œæ‹¬å·å†…çš„è‹±æ–‡ç¿»è¯‘ï¼Œä¾¿äºå¤–å›½äººé˜…è¯»ç†è§£ã€‚
    """
    temp_path = create_temp_file(image)
    prompt = """
ä½ æ˜¯ä¸€ä½å¯Œæœ‰åˆ›æ„çš„æ­Œæ›²å†™ä½œåŠ©æ‰‹ã€‚
è¯·è§‚å¯Ÿæˆ‘æä¾›çš„å›¾åƒï¼Œæ ¹æ®å›¾åƒå†…å®¹åˆ›ä½œä¸€é¦–ä¸­æ–‡æ­Œæ›²ã€‚è¦æ±‚å¦‚ä¸‹ï¼š
1. æ­Œè¯éœ€åŒ…å«ä¸åŒéƒ¨åˆ†ï¼Œå¦‚ã€ä¸»æ­Œã€‘ã€ã€å‰¯æ­Œã€‘ç­‰ã€‚
2. æ¯ä¸€å¥ä¸­æ–‡æ­Œè¯ä¸‹æ–¹è¯·å¦èµ·ä¸€è¡Œï¼Œç”¨æ‹¬å·æ‹¬ä½å¯¹åº”çš„è‹±æ–‡ç¿»è¯‘ï¼Œç¡®ä¿ä¸­æ–‡å’Œè‹±æ–‡åˆ†åˆ«ç‹¬å ä¸€è¡Œã€‚
3. æ­Œè¯è¦æ±‚å……æ»¡è¯—æ„ã€æ„å¢ƒæ·±è¿œã€æƒ…æ„ŸçœŸæŒšã€‚
è¯·åªè¾“å‡ºæ­Œè¯æ–‡æœ¬ï¼Œä¸è¦é¢å¤–è¯´æ˜ã€‚
    """
    stream = analyze_image_file(image_file=temp_path, model="llava:7b", user_prompt=prompt)
    parsed = stream_parser(stream)
    lyrics = "".join(parsed).strip()
    return lyrics.strip('"')


# =============== 2) ç”Ÿæˆæ­Œæ›²æ ‡é¢˜ (è°ƒç”¨ llava:7b) ===============
def generate_song_title(image: Image.Image) -> str:
    """è°ƒç”¨ llava:7b æ¨¡å‹ï¼Œä¸ºå›¾åƒç”Ÿæˆæ­Œæ›²æ ‡é¢˜ï¼ˆä¸­æ–‡ï¼‰ã€‚"""
    temp_path = create_temp_file(image)
    prompt = """
è¯·ä¸ºæˆ‘æä¾›ä¸€ä¸ªç®€æ´ã€å¯Œæœ‰è¯—æ„çš„ä¸­æ–‡æ­Œæ›²æ ‡é¢˜ï¼Œåªè¾“å‡ºæ ‡é¢˜ï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚
    """
    stream = analyze_image_file(image_file=temp_path, model="llava:7b", user_prompt=prompt)
    parsed = stream_parser(stream)
    title = "".join(parsed).strip()
    return title.strip('"')


# =============== 3) æ ¼å¼åŒ–æ­Œè¯ ===============
def format_text(text: str) -> str:
    """å»é™¤å¤šä½™ç©ºè¡Œï¼Œå¹¶ä¿è¯æ¯è¡Œé¦–å­—æ¯å¤§å†™ã€‚"""
    lines = [line.strip() for line in text.split("\n") if line.strip()]
    lines = [l[0].upper() + l[1:] if l else "" for l in lines]
    return "\n\n".join(lines)


# =============== 4) åŸºäºæ­Œè¯ç”ŸæˆåŒ¹é…çš„æ—‹å¾‹ MIDIï¼ˆå¸¦éŸ³èŠ‚åˆ° note.lyricï¼‰ ===============
def split_into_syllables(line: str) -> list:
    """å°†æ•´è¡Œæ‹†åˆ†ä¸ºéŸ³èŠ‚æˆ–å•è¯ã€‚"""
    dic = pyphen.Pyphen(lang='en')
    words = line.split()
    syllables = []
    for word in words:
        syl = dic.inserted(word)
        splitted = syl.split('-')
        print(f"[DEBUG] word={word}, splitted={splitted}")
        syllables.extend(splitted)
    return syllables

def generate_melody_for_line(line: str) -> list:
    """ç»™ä¸€è¡Œæ­Œè¯ç”ŸæˆéŸ³ç¬¦ï¼Œé»˜è®¤ä½¿ç”¨ C å¤§è°ƒï¼ˆC4~B4ï¼‰ï¼Œæ¯ä¸ªéŸ³èŠ‚1æ‹ã€‚"""
    scale_notes = ["C4", "D4", "E4", "F4", "G4", "A4", "B4"]
    syllables = split_into_syllables(line)
    melody = []
    for i, syl in enumerate(syllables):
        pitch = scale_notes[i % len(scale_notes)]
        melody.append((pitch, 1.0, syl))
    return melody

def generate_melody_from_lyrics(lyrics: str, debug_save: bool = False) -> bytes:
    from music21 import stream, note, instrument
    s = stream.Stream()
    inst = instrument.Instrument()
    inst.midiProgram = 53
    s.insert(0, inst)
    lines = [l for l in lyrics.split("\n") if l.strip()]
    for line in lines:
        melody_line = generate_melody_for_line(line)
        for (pitch, dur, syl) in melody_line:
            n = note.Note(pitch, quarterLength=dur)
            n.lyric = syl
            print(f"[DEBUG] note={pitch}, lyric={repr(syl)}")
            s.append(n)
    with tempfile.NamedTemporaryFile(suffix=".mid", delete=False) as tmp:
        midi_path = tmp.name
    s.write("midi", fp=midi_path)
    with open(midi_path, "rb") as f:
        midi_bytes = f.read()
    if debug_save:
        with open("debug_midi.mid", "wb") as debug_file:
            debug_file.write(midi_bytes)
        print("Saved debug_midi.mid")
    os.remove(midi_path)
    return midi_bytes

def generate_matched_melody(lyrics: str, debug_save: bool = False) -> bytes:
    return generate_melody_from_lyrics(lyrics, debug_save=debug_save)


# =============== 5) MIDI -> WAVï¼ˆç²—ç³™æ¼”å”±ï¼‰ ===============
def midi_to_wav(midi_bytes: bytes) -> bytes:
    with tempfile.NamedTemporaryFile(suffix=".mid", delete=False) as tmp_midi:
        midi_path = tmp_midi.name
        tmp_midi.write(midi_bytes)
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_wav:
        wav_path = tmp_wav.name
    fs = FluidSynth(sound_font=SOUNDFONT_PATH)
    fs.midi_to_audio(midi_path, wav_path)
    with open(wav_path, "rb") as f:
        wav_data = f.read()
    os.remove(midi_path)
    os.remove(wav_path)
    return wav_data


# =============== 6) DiffSinger æ¨ç†å‡½æ•° ===============
def diffsinger_infer(lyrics: str, config_path: str, model_path: str) -> bytes:
    """
    ä½¿ç”¨ DiffSinger ä»æ­Œè¯ç”Ÿæˆåˆæˆæ¼”å”±ã€‚
    æœ¬å‡½æ•°å‡å®šä½ å·²æœ‰ä¿®æ”¹åçš„ ds_e2e.py æ¨ç†è„šæœ¬ï¼Œ
    å®ƒæ¥å— --config, --model, --lyrics, --out å‚æ•°ç”Ÿæˆ WAV æ–‡ä»¶ã€‚
    """
    # å°†æ­Œè¯ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
    with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=False) as tmp:
        lyrics_file = tmp.name
        tmp.write(lyrics)
    
    # åˆ›å»ºä¸€ä¸ªä¸´æ—¶è¾“å‡ºæ–‡ä»¶
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_wav:
        out_wav = tmp_wav.name

    # æ„é€ æ¨ç†å‘½ä»¤
    cmd = [
        "/opt/anaconda3/envs/diffsinger_env/bin/python",
        "/Users/xiangxiaoxin/Documents/GitHub/DiffSinger/inference/svs/ds_e2e.py",
        "--config", "diffsinger/0228_opencpop_ds100_rel/config.yaml",
        "--model", "diffsinger/0228_opencpop_ds100_rel/model_ckpt_steps_160000.ckpt",
        "--lyrics", lyrics_file,
        "--out", out_wav
    ]
    
    try:
        # ä½¿ç”¨ DiffSinger æ ¹ç›®å½•ä½œä¸ºå·¥ä½œç›®å½•
        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE,
                                text=True, check=True, cwd="/Users/xiangxiaoxin/Documents/GitHub/DiffSinger")
        st.write("DiffSinger æ¨ç†è¾“å‡º:", result.stdout)
    except subprocess.CalledProcessError as e:
        st.error("DiffSinger æ¨ç†å¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯:")
        st.error(e.stderr)
        raise

    # è¯»å–ç”Ÿæˆçš„ WAV æ–‡ä»¶
    with open(out_wav, "rb") as f:
        wav_data = f.read()

    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    os.remove(lyrics_file)
    os.remove(out_wav)
    return wav_data



# =============== 7) Streamlit ä¸» UI ===============
col_left, col_right = st.columns([1.4, 1.6], gap="medium")

with col_left:
    st.markdown("**åœ¨è¿™é‡Œç”»ç”»**", unsafe_allow_html=True)
    st.write("é€‰æ‹©ç”»ç¬”é¢œè‰²å’Œç¬”åˆ·å¤§å°ï¼Œè‡ªç”±ç»˜åˆ¶åˆ›æ„ç”»é¢ã€‚")
    brush_color = st.color_picker("ç”»ç¬”é¢œè‰²", value="#000000")
    brush_size = st.slider("ç”»ç¬”å¤§å°", 1, 50, value=5)
    canvas_result = st_canvas(
        fill_color="rgba(255, 255, 255, 0)",
        stroke_width=brush_size,
        stroke_color=brush_color,
        background_color="white",
        update_streamlit=True,
        width=550,
        height=550,
        drawing_mode="freedraw",
        key="canvas",
    )

with col_right:
    st.markdown("**ç”Ÿæˆç»“æœ**", unsafe_allow_html=True)
    st.write("å®Œæˆç»˜ç”»åï¼Œç”Ÿæˆä¸­æ–‡æ­Œè¯åŠæ¯å¥å¯¹åº”çš„è‹±æ–‡ç¿»è¯‘ï¼Œå†ç”ŸæˆåŸºç¡€æ¼”å”±ï¼Œå¹¶ä½¿ç”¨ DiffSinger è½¬æ¢ä¸ºè‡ªç„¶çš„ä¸­æ–‡æ­Œå£°ï¼ˆåŒæ—¶é™„è‹±æ–‡ç¿»è¯‘ï¼‰ã€‚")
    
    # ç”Ÿæˆæ­Œè¯
    if st.button("ğŸ¶ ç”ŸæˆåŒè¯­æ­Œè¯"):
        if canvas_result.image_data is None:
            st.error("è¯·å…ˆåœ¨å·¦ä¾§ç”»å¸ƒä¸Šç»˜åˆ¶å†…å®¹ï¼")
        else:
            image = Image.fromarray((canvas_result.image_data * 255).astype(np.uint8)).convert("RGB")
            title = generate_song_title(image)
            raw_lyrics = generate_lyrics_with_ollama(image)
            lyrics = format_text(raw_lyrics)
            st.session_state["song_title"] = title
            st.session_state["lyrics"] = lyrics
    
    # æ˜¾ç¤ºç”Ÿæˆçš„æ­Œè¯å’Œæ ‡é¢˜
    if st.session_state["song_title"] and st.session_state["lyrics"]:
        st.markdown(f"**æ­Œæ›²æ ‡é¢˜ï¼š** {st.session_state['song_title']}", unsafe_allow_html=True)
        lyrics_html = st.session_state["lyrics"].replace("\n", "<br>")
        st.markdown(f"<div class='lyrics-container'><p>{lyrics_html}</p></div>", unsafe_allow_html=True)
    
    # ç”ŸæˆåŸºç¡€æ¼”å”±ï¼ˆMIDIâ†’WAVï¼‰
    if st.button("ğŸ¤ ç”ŸæˆåŸºç¡€æ¼”å”±"):
        if not st.session_state["lyrics"]:
            st.error("è¯·å…ˆç”Ÿæˆæ­Œè¯ï¼")
        else:
            midi_bytes = generate_matched_melody(st.session_state["lyrics"], debug_save=True)
            rough_wav = midi_to_wav(midi_bytes)
            st.audio(rough_wav, format="audio/wav")
            st.download_button("ä¸‹è½½åŸºç¡€æ¼”å”± WAV", rough_wav, "rough_melody.wav", mime="audio/wav")
    
    # ä½¿ç”¨ DiffSinger ç”Ÿæˆåˆæˆæ¼”å”±
    if st.button("ğŸ¤ ç”Ÿæˆ DiffSinger æ¼”å”±"):
        if not st.session_state["lyrics"]:
            st.error("è¯·å…ˆç”Ÿæˆæ­Œè¯ï¼")
        else:
            # è¯·å°†ä¸‹é¢çš„ config_path ä¸ model_path ä¿®æ”¹ä¸ºä½ è‡ªå·±çš„ DiffSinger é…ç½®æ–‡ä»¶ä¸æ¨¡å‹è·¯å¾„
            diffsinger_config = "/path/to/diffsinger/config.json"
            diffsinger_model = "/path/to/diffsinger/model.pth"
            synthesized_wav = diffsinger_infer(st.session_state["lyrics"], diffsinger_config, diffsinger_model)
            st.audio(synthesized_wav, format="audio/wav")
            st.download_button("ä¸‹è½½ DiffSinger æ¼”å”± WAV", synthesized_wav, "diffsinger_singing.wav", mime="audio/wav")
