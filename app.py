import os
import cv2
import dlib
import torch
import numpy as np
import gradio as gr
from torchvision import models, transforms
import ollama
from deepface import DeepFace

# -------------------------------
# 1ï¸âƒ£ é¢éƒ¨æ£€æµ‹ & æƒ…ç»ªè¯†åˆ«
# -------------------------------
PREDICTOR_PATH = os.path.join(os.path.dirname(__file__), "shape_predictor_68_face_landmarks.dat")
if not os.path.exists(PREDICTOR_PATH):
    raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ° {PREDICTOR_PATH}ï¼Œè¯·ç¡®ä¿æ–‡ä»¶å·²ä¸‹è½½ï¼")

detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor(PREDICTOR_PATH)

def detect_emotion(image_path):
    """ä½¿ç”¨ DeepFace è¿›è¡Œæƒ…ç»ªè¯†åˆ«"""
    analysis = DeepFace.analyze(img_path=image_path, actions=['emotion'], enforce_detection=False)
    return analysis[0]['dominant_emotion']

# -------------------------------
# 2ï¸âƒ£ é¢éƒ¨ç‰¹å¾æå–
# -------------------------------
def extract_facial_features(image_path):
    """ä½¿ç”¨ OpenCV å’Œ dlib æå–é¢éƒ¨ç‰¹å¾"""
    img = cv2.imread(image_path)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    faces = detector(gray)

    features = {
        "face_shape": "unknown",
        "skin_color": "unknown",
        "hair_color": "unknown",
        "facial_hair": "none",
        "nose_shape": "unknown",
        "glasses": "none",
        "symmetry": "unknown",
        "hat": "none"
    }

    for face in faces:
        landmarks = predictor(gray, face)
        features["face_shape"] = "oval" if landmarks.part(0).x < landmarks.part(16).x else "round"
        avg_color = np.mean(img, axis=(0, 1))
        features["skin_color"] = "light" if avg_color[2] > 160 else "dark"
        features["hair_color"] = "brown" if avg_color[0] > 80 else "black"
        features["facial_hair"] = "beard" if np.mean(gray[landmarks.part(8).y:landmarks.part(30).y, :]) < 90 else "none"
        features["glasses"] = "yes" if np.mean(gray[landmarks.part(36).y:landmarks.part(45).y, :]) < 50 else "none"
        features["hat"] = "yes" if np.mean(gray[:landmarks.part(19).y, :]) < 60 else "none"
    
    return features

# -------------------------------
# 3ï¸âƒ£ ç”Ÿæˆæ­Œè¯ (Ollama / Gemma:2b)
# -------------------------------
def generate_lyrics(facial_features, emotion):
    """ç»“åˆé¢éƒ¨ç‰¹å¾å’Œæƒ…ç»ªç”Ÿæˆä¼˜åŒ–åçš„æ­Œè¯"""
    
    prompt = f"""
    Write a poetic song inspired by folk storytelling, rich in imagery and emotion.
    The song is about a person with {facial_features['face_shape']} face, {facial_features['skin_color']} skin, {facial_features['hair_color']} hair, and wearing {facial_features['glasses']}.
    They are feeling {emotion}. 
    Use metaphor, symbolism, and vivid descriptions to enhance the lyrics.

    Structure the lyrics in a storytelling format:
    - [Verse 1] Introduce the scene and the main character's emotions.
    - [Chorus] A memorable, poetic refrain that captures the song's essence.
    - [Verse 2] Develop the narrative, adding depth and contrast.

    Example of the desired style:
    - Like Bob Dylan or Leonard Cohen, the lyrics should feel poetic, thoughtful, and evocative.
    - Ensure the lyrics follow a loose rhyme scheme (AABB or ABAB) but prioritize storytelling over strict rhyming.
    """
    
    response = ollama.chat(model="gemma:2b", messages=[{"role": "user", "content": prompt}])
    lyrics = response['message']['content']

    # ç¡®ä¿æ­Œè¯æ ¼å¼è‰¯å¥½
    lyrics = format_lyrics(lyrics)

    # é¿å…æ­Œè¯è¿‡çŸ­ï¼Œå¢åŠ ä¸€äº›è¯—æ„çš„ç»“å°¾
    if len(lyrics.split()) < 15:
        lyrics += "\nAnd so the night fades into longing, as the echoes of love remain."

    return lyrics

def format_lyrics(lyrics):
    """ä¼˜åŒ–æ­Œè¯æ ¼å¼ï¼Œä½¿å…¶æ›´æ•´é½ã€æ›´æœ‰è¯—æ„"""
    lines = lyrics.split("\n")
    formatted_lines = [line.strip().capitalize() for line in lines if line.strip()]
    return "\n".join(formatted_lines)


# -------------------------------
# 4ï¸âƒ£ Gradio ç•Œé¢
# -------------------------------
def process_image(image):
    """å®Œæ•´çš„ AI æ­Œè¯ç”Ÿæˆæµç¨‹"""
    cv2.imwrite("input.jpg", image)
      
    # æ£€æµ‹æƒ…ç»ª
    emotion = detect_emotion("input.jpg")
    print(f"ğŸ¤” è¯†åˆ«çš„æƒ…ç»ªï¼š{emotion}")  # âœ… æ‰“å°æƒ…ç»ªç»“æœ

    # æå–é¢éƒ¨ç‰¹å¾
    features = extract_facial_features("input.jpg")
    print(f"ğŸ“Œ æå–çš„é¢éƒ¨ç‰¹å¾ï¼š{features}")  # âœ… æ‰“å°é¢éƒ¨ç‰¹å¾
    
    # ç”Ÿæˆæ­Œè¯
    lyrics = generate_lyrics(features, emotion)

    return f"ğŸ­ è¯†åˆ«çš„æƒ…ç»ªï¼š{emotion}\nğŸ–¼ æå–çš„é¢éƒ¨ç‰¹å¾ï¼š{features}\nğŸ¶ ç”Ÿæˆçš„æ­Œè¯ï¼š\n{lyrics}"

interface = gr.Interface(
    fn=process_image,
    inputs=gr.Image(type="numpy"),
    outputs="text",
    title="AI æ­Œè¯ç”Ÿæˆå™¨",
    description="ä¸Šä¼ ä¸€å¼ ç…§ç‰‡ï¼ŒAI å°†æ ¹æ®ä½ çš„é¢éƒ¨ç‰¹å¾ç”Ÿæˆä¸€é¦–æ­Œè¯ ğŸµ"
)

if __name__ == "__main__":
    print("ğŸš€ Python è¿è¡ŒæˆåŠŸï¼")
    interface.launch()

