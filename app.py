import cv2
import torch
import numpy as np
import streamlit as st
from PIL import Image
import open_clip
from transformers import BlipProcessor, BlipForConditionalGeneration
from sklearn.cluster import KMeans  # é¢œè‰²æå–
import ollama  # æ­Œè¯ç”Ÿæˆ
from streamlit_drawable_canvas import st_canvas  # âœ… æ›¿æ¢ Gradio ç”»å¸ƒ

# -------------------------------
# 1ï¸âƒ£ è¯†åˆ«ç»˜ç”»å†…å®¹ (CLIP + BLIP)
# -------------------------------
device = "mps" if torch.backends.mps.is_available() else "cpu"
print(f"âœ… ä½¿ç”¨è®¾å¤‡: {device}")

# âœ… æ›¿æ¢ ViT-L/14 + æ›´å¼ºçš„é¢„è®­ç»ƒæ¨¡å‹
model, preprocess, tokenizer = open_clip.create_model_and_transforms(
    "ViT-L/14", pretrained="openai"
)
model.to(device)

# âœ… åˆå§‹åŒ– BLIPï¼ˆç”¨äºç”Ÿæˆå…·ä½“çš„ç”»é¢æè¿°ï¼‰
processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
blip_model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base").to(device)

def ensure_pil_image(image):
    """ç¡®ä¿ `image` æ˜¯ `PIL.Image` ç±»å‹"""
    if isinstance(image, np.ndarray):
        return Image.fromarray(image).convert("RGB")
    return image.convert("RGB")

def extract_visual_features(image):
    """æå–ç”»é¢é£æ ¼å…³é”®è¯ï¼ˆé¢œè‰²ã€çº¿æ¡ï¼‰"""
    image_np = np.array(image)
    gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
    
    # **é¢œè‰²é£æ ¼**
    kmeans = KMeans(n_clusters=3, random_state=0).fit(image_np.reshape(-1, 3))
    colors = kmeans.cluster_centers_.astype(int)
    warm_ratio = sum(1 for c in colors if c[0] > 150 and c[2] < 100) / 3
    dark_ratio = sum(1 for c in colors if sum(c) < 200) / 3
    color_desc = "æ¸©æš–è€Œå……æ»¡æ´»åŠ›" if warm_ratio > 0.5 else "æ·±æ²‰è€Œç¥ç§˜" if dark_ratio > 0.5 else "è‰²å½©å’Œè°"

    # **çº¿æ¡æ„Ÿè§‰**
    edges = cv2.Canny(gray, 50, 150)
    line_desc = "çº¿æ¡æµç•…è€Œè‡ªç”±" if np.count_nonzero(edges) > 10000 else "ç®€æ´è€Œå¯Œæœ‰è¡¨ç°åŠ›"

    return f"{color_desc}ï¼Œ{line_desc}"

def describe_image_with_blip(image):
    """ä½¿ç”¨ BLIP ç”Ÿæˆæ›´ä¸°å¯Œçš„ç”»é¢æè¿°"""
    inputs = processor(image, return_tensors="pt").to(device)
    with torch.no_grad():
        caption = blip_model.generate(**inputs, max_length=50, do_sample=True, temperature=0.9)
    return processor.decode(caption[0], skip_special_tokens=True)

def analyze_painting(image):
    """ç”Ÿæˆç”»é¢æè¿°"""
    image = ensure_pil_image(image)
    print(f"âœ… è½¬æ¢å image ç±»å‹: {type(image)}")

    image_tensor = preprocess(image).unsqueeze(0).to(device)
    blip_description = describe_image_with_blip(image)

    descriptions = ["è‡ªç”±è€Œè¶…ç°å®", "æ¢¦å¹»è€Œå¥‡å¦™", "å……æ»¡æ´»åŠ›", "ç¥ç§˜è€Œæ·±é‚ƒ", "æŠ½è±¡è€Œå¯Œæœ‰å¼ åŠ›"]
    text_tokens = open_clip.tokenize(descriptions).to(device)
    
    with torch.no_grad():
        similarity = (model.encode_image(image_tensor) @ model.encode_text(text_tokens).T).softmax(dim=-1)

    clip_keyword = descriptions[similarity.argmax().item()]
    visual_keywords = extract_visual_features(image)

    return f"{blip_description}ï¼Œ{clip_keyword}ï¼Œ{visual_keywords}"

# -------------------------------
# 2ï¸âƒ£ ç”Ÿæˆæ­Œè¯ (Ollama / Gemma:2b)
# -------------------------------
def generate_lyrics(painting_description):
    """æ ¹æ®ç”»é¢æè¿°ç”Ÿæˆè¯—æ„æ­Œè¯"""
    
    prompt = f"""
    Write a poetic song inspired by this description:
    "{painting_description}"
    
    - Capture the **emotions** of the scene rather than describing it directly.
    - Use **imagery and symbolism** to create a story inspired by the painting.
    - The song should feel like a **mystical journey**, **a lonely adventure**, or **a dreamy reflection**.
    - Avoid generic words like "masterpiece" or "paintbrush". Instead, use metaphors related to art, light, and nature.
    
    Suggested format:
    
    **[Verse 1]**  
    Set the mood with visual imagery and emotional depth.  
    Introduce a **mystical character** (a lost wolf, a wandering artist, a floating soul).  
    
    **[Chorus]**  
    A repeated poetic line that captures the essence of the song.  
    
    **[Verse 2]**  
    Expand on the emotional journey, using **contrast and tension**.  
    
    Examples of poetic styles:  
    - Dreamlike and surreal (e.g., "a golden thread weaves through the sky")  
    - Mysterious and melancholic (e.g., "shadows whisper forgotten names")  
    - Soft and reflective (e.g., "memories drift like paper boats on water")  
    
    **Write in a loose poetic structure, prioritizing storytelling over rhyme.**  
    """

    response = ollama.chat(model="gemma:2b", messages=[{"role": "user", "content": prompt}])
    lyrics = response['message']['content']
    
    return format_lyrics(lyrics)

def format_lyrics(lyrics):
    """ä¼˜åŒ–æ­Œè¯æ ¼å¼ï¼Œä½¿å…¶æ›´ç¾è§‚"""
    lines = lyrics.split("\n")
    formatted_lines = [line.strip().capitalize() for line in lines if line.strip()]
    return "\n".join(formatted_lines)

# -------------------------------
# 3ï¸âƒ£ Streamlit ç•Œé¢ (æ”¯æŒé¢œè‰² & ç”»ç¬”è°ƒèŠ‚)
# -------------------------------
st.title("ğŸ¨ AI ç»˜ç”»æ­Œè¯ç”Ÿæˆå™¨")
st.write("åœ¨ç”»å¸ƒä¸Šè‡ªç”±ç»˜ç”»ï¼Œæ”¯æŒé¢œè‰²å’Œç¬”åˆ·è°ƒæ•´ï¼ŒAI å°†ç”Ÿæˆæ­Œè¯ ğŸµ")

# é¢œè‰²é€‰æ‹© & ç”»ç¬”å¤§å°
color = st.color_picker("é€‰æ‹©ç”»ç¬”é¢œè‰²", "#000000")
brush_size = st.slider("ç”»ç¬”å¤§å°", 1, 50, 5)

# ç”»å¸ƒç»„ä»¶
canvas_result = st_canvas(
    fill_color="rgba(255, 255, 255, 0)",  # é€æ˜èƒŒæ™¯
    stroke_width=brush_size,
    stroke_color=color,
    background_color="white",
    update_streamlit=True,
    width=512,
    height=512,
    drawing_mode="freedraw",
    key="canvas",
)

# æäº¤æŒ‰é’®
if st.button("ğŸ¶ ç”Ÿæˆæ­Œè¯"):
    if canvas_result.image_data is not None:
        image = Image.fromarray((canvas_result.image_data * 255).astype(np.uint8)).convert("RGB")
        painting_description = analyze_painting(image)
        lyrics = generate_lyrics(painting_description)

        st.subheader("ğŸ¨ è¯†åˆ«çš„ç»˜ç”»é£æ ¼")
        st.write(painting_description)

        st.subheader("ğŸ¶ ç”Ÿæˆçš„æ­Œè¯")
        st.write(lyrics)
    else:
        st.error("è¯·å…ˆåœ¨ç”»å¸ƒä¸Šç»˜åˆ¶å†…å®¹ï¼")
