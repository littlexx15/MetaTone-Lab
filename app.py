import cv2
import torch
import numpy as np
import streamlit as st
from PIL import Image
import open_clip
from transformers import BlipProcessor, BlipForConditionalGeneration
from sklearn.cluster import KMeans  # é¢œè‰²æå–
import ollama  # æ­Œè¯ç”Ÿæˆ
from streamlit_drawable_canvas import st_canvas  # æ›¿æ¢ Gradio ç”»å¸ƒ

# -------------------------------
# 1ï¸âƒ£ ç¼“å­˜åŠ è½½æ¨¡å‹ï¼Œé¿å…é‡å¤åŠ è½½è€—æ—¶
# -------------------------------
@st.cache_resource
def load_models_and_device():
    device = "mps" if torch.backends.mps.is_available() else "cpu"
    print(f"âœ… ä½¿ç”¨è®¾å¤‡: {device}")

    # åŠ è½½ OpenCLIP æ¨¡å‹
    model, preprocess, tokenizer = open_clip.create_model_and_transforms(
        "ViT-L/14", pretrained="openai"
    )
    model.to(device)

    # åŠ è½½ BLIP æ¨¡å‹
    processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
    blip_model = BlipForConditionalGeneration.from_pretrained(
        "Salesforce/blip-image-captioning-base"
    ).to(device)

    return device, model, preprocess, tokenizer, processor, blip_model

device, model, preprocess, tokenizer, processor, blip_model = load_models_and_device()

# -------------------------------
# 2ï¸âƒ£ åŠŸèƒ½å‡½æ•°
# -------------------------------
def ensure_pil_image(image):
    """ç¡®ä¿ image æ˜¯ PIL.Image ç±»å‹"""
    if isinstance(image, np.ndarray):
        return Image.fromarray(image).convert("RGB")
    return image.convert("RGB")

def extract_visual_features(image):
    """æå–ç”»é¢é£æ ¼å…³é”®è¯ï¼ˆé¢œè‰²ã€çº¿æ¡ï¼‰"""
    image_np = np.array(image)
    gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
    
    # é¢œè‰²é£æ ¼
    kmeans = KMeans(n_clusters=3, random_state=0).fit(image_np.reshape(-1, 3))
    colors = kmeans.cluster_centers_.astype(int)
    warm_ratio = sum(1 for c in colors if c[0] > 150 and c[2] < 100) / 3
    dark_ratio = sum(1 for c in colors if sum(c) < 200) / 3
    color_desc = "æ¸©æš–è€Œå……æ»¡æ´»åŠ›" if warm_ratio > 0.5 else "æ·±æ²‰è€Œç¥ç§˜" if dark_ratio > 0.5 else "è‰²å½©å’Œè°"

    # çº¿æ¡æ„Ÿè§‰
    edges = cv2.Canny(gray, 50, 150)
    line_desc = "çº¿æ¡æµç•…è€Œè‡ªç”±" if np.count_nonzero(edges) > 10000 else "ç®€æ´è€Œå¯Œæœ‰è¡¨ç°åŠ›"

    return f"{color_desc}ï¼Œ{line_desc}"

def describe_image_with_blip(image):
    """ä½¿ç”¨ BLIP ç”Ÿæˆæ›´ä¸°å¯Œçš„ç”»é¢æè¿°"""
    inputs = processor(image, return_tensors="pt").to(device)
    with torch.no_grad():
        caption = blip_model.generate(**inputs, max_length=50, do_sample=True, temperature=0.9)
    return processor.decode(caption[0], skip_special_tokens=True)

def analyze_painting(image):
    """ç”Ÿæˆç”»é¢æè¿°"""
    image = ensure_pil_image(image)
    print(f"âœ… è½¬æ¢å image ç±»å‹: {type(image)}")

    image_tensor = preprocess(image).unsqueeze(0).to(device)
    blip_description = describe_image_with_blip(image)

    descriptions = ["è‡ªç”±è€Œè¶…ç°å®", "æ¢¦å¹»è€Œå¥‡å¦™", "å……æ»¡æ´»åŠ›", "ç¥ç§˜è€Œæ·±é‚ƒ", "æŠ½è±¡è€Œå¯Œæœ‰å¼ åŠ›"]
    text_tokens = open_clip.tokenize(descriptions).to(device)
    
    with torch.no_grad():
        similarity = (model.encode_image(image_tensor) @ model.encode_text(text_tokens).T).softmax(dim=-1)

    clip_keyword = descriptions[similarity.argmax().item()]
    visual_keywords = extract_visual_features(image)

    return f"{blip_description}ï¼Œ{clip_keyword}ï¼Œ{visual_keywords}"

def generate_lyrics(painting_description):
    """æ ¹æ®ç”»é¢æè¿°ç”Ÿæˆè¯—æ„æ­Œè¯"""
    prompt = f"""
    Write a poetic song inspired by this description:
    "{painting_description}"
    
    - Capture the **emotions** of the scene rather than describing it directly.
    - Use **imagery and symbolism** to create a story inspired by the painting.
    - The song should feel like a **mystical journey**, **a lonely adventure**, or **a dreamy reflection**.
    - Avoid generic words like "masterpiece" or "paintbrush". Instead, use metaphors related to art, light, and nature.
    
    Suggested format:
    
    **[Verse 1]**  
    Set the mood with visual imagery and emotional depth.  
    Introduce a **mystical character** (a lost wolf, a wandering artist, a floating soul).  
    
    **[Chorus]**  
    A repeated poetic line that captures the essence of the song.  
    
    **[Verse 2]**  
    Expand on the emotional journey, using **contrast and tension**.  
    
    Examples of poetic styles:  
    - Dreamlike and surreal (e.g., "a golden thread weaves through the sky")  
    - Mysterious and melancholic (e.g., "shadows whisper forgotten names")  
    - Soft and reflective (e.g., "memories drift like paper boats on water")  
    
    **Write in a loose poetic structure, prioritizing storytelling over rhyme.**  
    """
    response = ollama.chat(model="gemma:2b", messages=[{"role": "user", "content": prompt}])
    lyrics = response['message']['content']
    return format_lyrics(lyrics)

def format_lyrics(lyrics):
    """ä¼˜åŒ–æ­Œè¯æ ¼å¼"""
    lines = lyrics.split("\n")
    formatted_lines = [line.strip().capitalize() for line in lines if line.strip()]
    return "\n".join(formatted_lines)

# -------------------------------
# 3ï¸âƒ£ Streamlit ç•Œé¢ï¼ˆé›†æˆæ§ä»¶å’Œç”»å¸ƒï¼‰
# -------------------------------
st.title("ğŸ¨ AI ç»˜ç”»æ­Œè¯ç”Ÿæˆå™¨")
st.write("ç›´æ¥åœ¨ä¸‹æ–¹è°ƒæ•´é¢œè‰²å’Œç¬”åˆ·å¤§å°ï¼Œç„¶åå¼€å§‹ç»˜ç”»ï¼ŒAI å°†ç”Ÿæˆæ­Œè¯ ğŸµ")

# å°†é¢œè‰²é€‰æ‹©å’Œç¬”åˆ·å¤§å°æ§ä»¶æ”¾åœ¨ç”»å¸ƒä¸Šæ–¹
brush_color = st.color_picker("é€‰æ‹©ç”»ç¬”é¢œè‰²", value="#000000")
brush_size = st.slider("ç”»ç¬”å¤§å°", 1, 50, value=5)

# æç¤ºï¼šæ¯æ¬¡è°ƒæ•´é¢œè‰²æˆ–ç¬”åˆ·å¤§å°ä¼šé‡è½½ç”»å¸ƒï¼Œå¯èƒ½å¯¼è‡´å½“å‰ç»˜å›¾å†…å®¹è¢«æ¸…ç©ºï¼
canvas_result = st_canvas(
    fill_color="rgba(255, 255, 255, 0)",
    stroke_width=brush_size,
    stroke_color=brush_color,
    background_color="white",
    update_streamlit=True,  # å¼€å¯å®æ—¶æ›´æ–°ï¼Œå®æ—¶ä¼ è¾“æ¯ä¸€ç¬”
    width=512,
    height=512,
    drawing_mode="freedraw",
    key="canvas"  # å›ºå®š key å°½é‡ä¿ç•™çŠ¶æ€
)

if st.button("ğŸ¶ ç”Ÿæˆæ­Œè¯"):
    if canvas_result.image_data is not None:
        image = Image.fromarray((canvas_result.image_data * 255).astype(np.uint8)).convert("RGB")
        painting_description = analyze_painting(image)
        lyrics = generate_lyrics(painting_description)
        st.subheader("ğŸ¨ è¯†åˆ«çš„ç»˜ç”»é£æ ¼")
        st.write(painting_description)
        st.subheader("ğŸ¶ ç”Ÿæˆçš„æ­Œè¯")
        st.write(lyrics)
    else:
        st.error("è¯·å…ˆåœ¨ç”»å¸ƒä¸Šç»˜åˆ¶å†…å®¹ï¼")
