import numpy as np
import streamlit as st
from PIL import Image
from streamlit_drawable_canvas import st_canvas

import random
import music21
import tempfile
import os

import pyphen  # ç”¨äºéŸ³èŠ‚æ‹†åˆ†
from midi2audio import FluidSynth  # å°† MIDI è½¬ WAV

from util.image_helper import create_temp_file
from util.llm_helper import analyze_image_file, stream_parser

# åœ¨è¿™é‡Œå¡«å¥½ä½ çš„ SoundFont è·¯å¾„ï¼ˆä¾‹å¦‚é€šç”¨ GM æˆ–äººå£°éŸ³è‰²çš„ SoundFontï¼‰
SOUNDFONT_PATH = "/Users/xiangxiaoxin/Documents/GitHub/FaceTune/soundfonts/VocalsPapel.sf2"

# ----------------------------------------
# ä½¿ç”¨ session_state å­˜å‚¨å½“å‰ç”Ÿæˆçš„æ­Œè¯å’Œæ ‡é¢˜
# ----------------------------------------
if "lyrics" not in st.session_state:
    st.session_state["lyrics"] = None
if "song_title" not in st.session_state:
    st.session_state["song_title"] = None

# -------------------------------
# é¡µé¢å¸ƒå±€ä¸å…¨å±€æ ·å¼
# -------------------------------
st.set_page_config(
    page_title="MetaTone Lab",
    layout="wide",
)

st.markdown(
    """
    <style>
    .main .block-container {
        max-width: 1200px;
        margin: auto;
    }
    h1 {
        text-align: center;
        font-size: 36px !important;
        margin-bottom: 0.2em;
    }
    .subheader-text {
        font-size: 20px;
        font-weight: bold;
        margin-bottom: 0.6em;
        margin-top: 0.2em;
    }
    .song-title {
        font-size: 24px;
        font-weight: bold;
        margin-top: 0.5em;
        margin-bottom: 0.5em;
    }
    .lyrics-container {
        height: 500px;
        overflow-y: auto;
        padding-right: 1em;
        margin-top: 10px;
        border: 1px solid #ccc;
        border-radius: 5px;
    }
    .lyrics-container p {
        line-height: 1.6;
        margin-bottom: 0.8em;
        margin-left: 0.5em;
        margin-right: 0.5em;
    }
    .stButton {
        margin-top: 1em;
        margin-bottom: 1em;
    }
    div[data-baseweb="slider"] {
        width: 500px !important;
    }
    </style>
    """,
    unsafe_allow_html=True
)

st.markdown("<h1>MetaTone å®éªŒå®¤</h1>", unsafe_allow_html=True)

# -------------------------------
# 1ï¸âƒ£ ç”Ÿæˆæ­Œè¯ï¼ˆè°ƒç”¨ llava:7bï¼‰
# -------------------------------
def generate_lyrics_with_ollama(image: Image.Image) -> str:
    temp_path = create_temp_file(image)
    prompt = """
You are a creative songwriting assistant.
Please look at the image I provide and write a structured poetic song inspired by the visual content.

**Requirements**:
1. The song must include [Verse], [Chorus], and optionally [Bridge].
2. Capture deep emotions, vivid imagery, and a dynamic sense of movement.
3. Each section should introduce new elements, avoiding repetitive phrases.
4. Keep lines concise, naturally rhythmic, and easy to sing.
5. Verses should be introspective and descriptive, while the chorus should be impactful, emotionally intense, and memorable.
6. Build emotional tension and resolution within the narrative.

Now here is the image:
    """
    stream = analyze_image_file(
        image_file=temp_path,
        model="llava:7b",
        user_prompt=prompt
    )
    parsed = stream_parser(stream)
    lyrics = "".join(parsed).strip()
    return lyrics.strip('"')  # å»æ‰é¦–å°¾å¼•å·

# -------------------------------
# 2ï¸âƒ£ ç”Ÿæˆæ­Œæ›²æ ‡é¢˜ï¼ˆè°ƒç”¨ llava:7bï¼‰
# -------------------------------
def generate_song_title(image: Image.Image) -> str:
    temp_path = create_temp_file(image)
    prompt = """
Provide a concise, creative, and poetic song title. Only output the title, with no extra words or disclaimers.
    """
    stream = analyze_image_file(
        image_file=temp_path,
        model="llava:7b",
        user_prompt=prompt
    )
    parsed = stream_parser(stream)
    title = "".join(parsed).strip()
    return title.strip('"')

# -------------------------------
# 3ï¸âƒ£ æ ¼å¼åŒ–æ­Œè¯
# -------------------------------
def format_text(text: str) -> str:
    lines = [line.strip() for line in text.split("\n") if line.strip()]
    lines = [l[0].upper() + l[1:] if l else "" for l in lines]
    return "\n\n".join(lines)

# -------------------------------
# 4ï¸âƒ£ æ–°æ–¹æ³•ï¼šåŸºäºæ­Œè¯éŸ³èŠ‚ç”ŸæˆåŒ¹é…çš„æ—‹å¾‹ MIDI
# -------------------------------

# ä½¿ç”¨ pyphen å¯¹å•è¡Œæ­Œè¯è¿›è¡ŒéŸ³èŠ‚æ‹†åˆ†
def split_into_syllables(line: str) -> list:
    dic = pyphen.Pyphen(lang='en')
    # å°†å•è¯ç”¨è¿å­—ç¬¦æ‹†åˆ†
    words = line.split()
    syllables = []
    for word in words:
        syl = dic.inserted(word)
        syllables.extend(syl.split('-'))
    return syllables

# ä¸ºä¸€è¡Œæ­Œè¯ç”Ÿæˆå¯¹åº”çš„æ—‹å¾‹ï¼ˆæ¯ä¸ªéŸ³èŠ‚ä¸€ä¸ªéŸ³ç¬¦ï¼‰
def generate_melody_for_line(line: str) -> list:
    syllables = split_into_syllables(line)
    melody = []
    # è¿™é‡Œå®šä¹‰ä¸€ä¸ªå›ºå®šçš„éŸ³é˜¶ï¼Œå¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´
    scale_notes = ["C4", "D4", "E4", "F4", "G4", "A4", "B4"]
    # ç®€å•ç¤ºä¾‹ï¼šä¾æ¬¡ä¸ºæ¯ä¸ªéŸ³èŠ‚åˆ†é…éŸ³é«˜ï¼ˆå¯é€‰ï¼šä½ ä¹Ÿå¯ä»¥åšéšæœºæˆ–å…¶ä»–é€»è¾‘ï¼‰
    for i, syl in enumerate(syllables):
        pitch = scale_notes[i % len(scale_notes)]
        melody.append((pitch, 1.0))  # (éŸ³é«˜, æ—¶å€¼)
    return melody

# æ ¹æ®æ•´é¦–æ­Œè¯ç”ŸæˆåŒ¹é…çš„ MIDI
def generate_melody_from_lyrics(lyrics: str) -> bytes:
    from music21 import stream, note, instrument
    s = stream.Stream()
    
    # æŒ‡å®šä¹å™¨ï¼ˆä¾‹å¦‚ Voice Oohsï¼Œå¯¹åº” GM Program 53ï¼‰
    inst = instrument.Instrument()
    inst.midiProgram = 53  # æ ¹æ®ä½ çš„ SoundFont è°ƒæ•´
    s.insert(0, inst)
    
    lines = [l for l in lyrics.split("\n") if l.strip()]
    for line in lines:
        melody = generate_melody_for_line(line)
        for pitch, duration in melody:
            n = note.Note(pitch, quarterLength=duration)
            # å¯é€‰æ‹©åªåœ¨æ¯è¡Œçš„ç¬¬ä¸€ä¸ªéŸ³ç¬¦ä¸Šæ·»åŠ æ­Œè¯
            n.lyric = line  
            s.append(n)
    
    with tempfile.NamedTemporaryFile(suffix=".mid", delete=False) as tmp:
        midi_path = tmp.name
    s.write("midi", fp=midi_path)
    
    with open(midi_path, "rb") as f:
        midi_bytes = f.read()
    os.remove(midi_path)
    return midi_bytes

# åŒ…è£…æˆç”ŸæˆåŒ¹é…æ—‹å¾‹çš„å‡½æ•°
def generate_matched_melody(lyrics: str) -> bytes:
    return generate_melody_from_lyrics(lyrics)

# -------------------------------
# 5ï¸âƒ£ MIDI è½¬ WAV
# -------------------------------
def midi_to_wav(midi_bytes: bytes) -> bytes:
    with tempfile.NamedTemporaryFile(suffix=".mid", delete=False) as tmp_midi:
        tmp_midi.write(midi_bytes)
        midi_path = tmp_midi.name

    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_wav:
        wav_path = tmp_wav.name

    fs = FluidSynth(sound_font=SOUNDFONT_PATH)
    fs.midi_to_audio(midi_path, wav_path)

    with open(wav_path, "rb") as f:
        wav_data = f.read()

    os.remove(midi_path)
    os.remove(wav_path)
    return wav_data

# -------------------------------
# 6ï¸âƒ£ Streamlit ä¸»å¸ƒå±€
# -------------------------------
col_left, col_right = st.columns([1.4, 1.6], gap="medium")

# å·¦ä¾§ï¼šç»˜ç”»åŒºåŸŸ
with col_left:
    st.markdown("<div class='subheader-text'>åœ¨è¿™é‡Œç”»ç”»</div>", unsafe_allow_html=True)
    st.write("é€‰æ‹©ç”»ç¬”é¢œè‰²å’Œç¬”åˆ·å¤§å°ï¼Œè‡ªç”±ç»˜åˆ¶åˆ›æ„ç”»é¢ã€‚")
    brush_color = st.color_picker("ç”»ç¬”é¢œè‰²", value="#000000")
    brush_size = st.slider("ç”»ç¬”å¤§å°", 1, 50, value=5)
    canvas_result = st_canvas(
        fill_color="rgba(255, 255, 255, 0)",
        stroke_width=brush_size,
        stroke_color=brush_color,
        background_color="white",
        update_streamlit=True,
        width=550,
        height=550,
        drawing_mode="freedraw",
        key="canvas",
    )

# å³ä¾§ï¼šç”Ÿæˆç»“æœåŒºåŸŸ
with col_right:
    st.markdown("<div class='subheader-text'>ç”Ÿæˆç»“æœ</div>", unsafe_allow_html=True)
    st.write("ç‚¹å‡»ã€ç”Ÿæˆæ­Œè¯ã€‘ç”Ÿæˆæ­Œæ›²æ ‡é¢˜å’Œæ­Œè¯ï¼›ç‚¹å‡»ã€ç”Ÿæˆæ¼”å”±ã€‘ç”Ÿæˆä¸æ­Œè¯åŒ¹é…çš„æ—‹å¾‹æ¼”å”±ã€‚")

    # æŒ‰é’®ï¼šç”Ÿæˆæ­Œè¯
    if st.button("ğŸ¶ ç”Ÿæˆæ­Œè¯"):
        if canvas_result.image_data is None:
            st.error("è¯·å…ˆåœ¨å·¦ä¾§ç”»å¸ƒä¸Šç»˜åˆ¶å†…å®¹ï¼")
        else:
            image = Image.fromarray((canvas_result.image_data * 255).astype(np.uint8)).convert("RGB")
            title = generate_song_title(image)
            raw_lyrics = generate_lyrics_with_ollama(image)
            lyrics = format_text(raw_lyrics)
            st.session_state["song_title"] = title
            st.session_state["lyrics"] = lyrics

    # å¦‚æœå·²æœ‰æ­Œè¯å’Œæ ‡é¢˜ï¼Œåˆ™æ˜¾ç¤º
    if st.session_state["song_title"] and st.session_state["lyrics"]:
        st.markdown("**æ­Œæ›²æ ‡é¢˜ï¼š**", unsafe_allow_html=True)
        st.markdown(f"<div class='song-title'>{st.session_state['song_title']}</div>", unsafe_allow_html=True)
        st.markdown("**ç”Ÿæˆçš„æ­Œè¯ï¼š**", unsafe_allow_html=True)
        lyrics_html = st.session_state["lyrics"].replace("\n", "<br>")
        st.markdown(f"<div class='lyrics-text lyrics-container'><p>{lyrics_html}</p></div>", unsafe_allow_html=True)

    # æŒ‰é’®ï¼šç”Ÿæˆæ¼”å”±ï¼ˆå§‹ç»ˆæ˜¾ç¤ºï¼Œä½†ç‚¹å‡»æ—¶æ£€æŸ¥æ˜¯å¦æœ‰æ­Œè¯ï¼‰
    if st.button("ğŸ¤ ç”Ÿæˆæ¼”å”±"):
        if not st.session_state["lyrics"]:
            st.error("è¯·å…ˆç”Ÿæˆæ­Œè¯ï¼")
        else:
            midi_bytes = generate_matched_melody(st.session_state["lyrics"])
            wav_data = midi_to_wav(midi_bytes)
            st.audio(wav_data, format="audio/wav")
            st.download_button(
                label="ä¸‹è½½ WAV éŸ³é¢‘",
                data=wav_data,
                file_name="matched_melody.wav",
                mime="audio/wav"
            )
