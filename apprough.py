@ -64,13 +64,12 @@ def extract_facial_features(image_path):
# -------------------------------
# 3ï¸âƒ£ ç”Ÿæˆæ­Œè¯ï¼ˆOllama / Gemma:2bï¼‰
# -------------------------------
def generate_lyrics(facial_features):
    """ç¡®ä¿æ­Œè¯é•¿åº¦è¶³å¤Ÿ"""
    prompt = f"A poetic song (at least 15 words) about a person with {facial_features['face_shape']} face and {facial_features['skin_color']} skin."
def generate_lyrics(facial_features, emotion):
    """ç»“åˆé¢éƒ¨ç‰¹å¾å’Œæƒ…ç»ªç”Ÿæˆæ­Œè¯"""
    prompt = f"A poetic song about a person with {facial_features['face_shape']} face and {facial_features['skin_color']} skin, feeling {emotion}."
    
    response = ollama.chat(model="gemma:2b", messages=[{"role": "user", "content": prompt}])
    
    # ç¡®ä¿æ­Œè¯è¶³å¤Ÿé•¿
    lyrics = response['message']['content']
    if len(lyrics.split()) < 15:
        lyrics += " This song is full of emotions and melodies that flow smoothly."
@ -78,6 +77,7 @@ def generate_lyrics(facial_features):
    return lyrics



# -------------------------------
# 4ï¸âƒ£ ç”Ÿæˆæ—‹å¾‹ï¼ˆPyTorch ç‰ˆéŸ³ä¹ç”Ÿæˆï¼‰
# -------------------------------
@ -105,17 +105,16 @@ def generate_melody(emotion):


# -------------------------------
# 5ï¸âƒ£ ä½¿ç”¨ Speedy-Speech è¿›è¡Œæ­Œæ›²åˆæˆ
# 5ï¸âƒ£ ä½¿ç”¨ FastPitch è¿›è¡Œæ­Œæ›²åˆæˆ
# -------------------------------
def synthesize_song(lyrics, melody_path):
    """ä½¿ç”¨ Speedy-Speech è¿›è¡Œæ­Œå”±åˆæˆ"""
    """ä½¿ç”¨ FastPitch è¿›è¡Œè¯­éŸ³åˆæˆ"""
    
    # åŠ è½½ Speedy-Speech
    tts = TTS("tts_models/en/ljspeech/speedy-speech")  # âœ… æ— éœ€ espeak-ng

    # ç”Ÿæˆæ­Œå”±è¯­éŸ³
    tts = TTS("tts_models/en/ljspeech/fast_pitch")  # âœ… æ”¹ç”¨ FastPitchï¼Œé€Ÿåº¦æ›´å¿«
    output_wav = "output.wav"
    tts.tts_to_file(text=lyrics, file_path=output_wav)
    
    # ç”Ÿæˆè¯­éŸ³å¹¶åŠ å¿«è¯­é€Ÿï¼Œé˜²æ­¢å£°éŸ³æ‹‰é•¿
    tts.tts_to_file(text=lyrics, file_path=output_wav, speed=1.1, max_decoder_steps=500)

    return output_wav

@ -127,14 +126,26 @@ def synthesize_song(lyrics, melody_path):
def process_image(image):
    """å®Œæ•´çš„ AI éŸ³ä¹ç”Ÿæˆæµç¨‹"""
    cv2.imwrite("input.jpg", image)
      
    # æ£€æµ‹æƒ…ç»ª
    emotion = detect_emotion("input.jpg")
    print(f"ğŸ§ è¯†åˆ«çš„æƒ…ç»ªï¼š{emotion}")  # âœ… æ‰“å°æƒ…ç»ªè¯†åˆ«ç»“æœ

    # æå–é¢éƒ¨ç‰¹å¾
    features = extract_facial_features("input.jpg")
    lyrics = generate_lyrics(features)
    
    # ç”Ÿæˆæ­Œè¯ï¼ˆç»“åˆé¢éƒ¨ç‰¹å¾ & æƒ…ç»ªï¼‰
    lyrics = generate_lyrics(features, emotion)
    
    # ç”Ÿæˆæ—‹å¾‹ï¼ˆåŸºäºæƒ…ç»ªï¼‰
    melody = generate_melody(emotion)
    
    # åˆæˆæ­Œæ›²
    song = synthesize_song(lyrics, melody)
    
    return lyrics, melody, song


interface = gr.Interface(
    fn=process_image,
    inputs=gr.Image(type="numpy"),
